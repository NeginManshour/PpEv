{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f9f02e1-a01b-4c21-8b27-ad7c7e32e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load configuration and define a global variable\n",
    "def load_config():\n",
    "    global config\n",
    "    with open('config_Haddock.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "\n",
    "# Call the function to load the configuration\n",
    "load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea14cc83-647f-4d6d-93c1-9bfe451810ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load configuration and define a global variable\n",
    "def load_config():\n",
    "    global config\n",
    "    with open('config_Haddock.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "\n",
    "# Call the function to load the configuration\n",
    "load_config()\n",
    "\n",
    "def convert_tsv_to_excel(source_directory, target_directory, subdirectory_name):\n",
    "    \"\"\"\n",
    "    Converts all TSV files found in the source_directory into Excel files\n",
    "    and saves them into the target_directory along with a specified subdirectory.\n",
    "\n",
    "    Args:\n",
    "    - source_directory (str): The path to the directory containing TSV files.\n",
    "    - target_directory (str): The path to the directory where Excel files will be saved.\n",
    "    - subdirectory_name (str): The name of the subdirectory where Excel files will be placed.\n",
    "    \"\"\"\n",
    "    # Append the subdirectory to the target directory\n",
    "    full_target_directory = os.path.join(target_directory, subdirectory_name)\n",
    "    \n",
    "    # Ensure the target directory exists\n",
    "    if not os.path.exists(full_target_directory):\n",
    "        os.makedirs(full_target_directory)\n",
    "    \n",
    "    # Iterate over all files in the source directory\n",
    "    for filename in os.listdir(source_directory):\n",
    "        if filename.endswith('.tsv'):\n",
    "            # Construct the full file paths\n",
    "            source_file_path = os.path.join(source_directory, filename)\n",
    "            # Change the file extension from .tsv to .xlsx for the output file\n",
    "            target_file_path = os.path.join(full_target_directory, filename.replace('.tsv', '.xlsx'))\n",
    "            \n",
    "            # Load the TSV file\n",
    "            df = pd.read_csv(source_file_path, sep='\\t')\n",
    "            # Save the dataframe to an Excel file\n",
    "            df.to_excel(target_file_path, index=False)\n",
    "            \n",
    "            # Optionally print a confirmation message\n",
    "            #print(f'Converted {filename} to Excel and saved as {os.path.basename(target_file_path)}')\n",
    "\n",
    "# Example usage\n",
    "source_directory = config['Haddock_em_directory']\n",
    "target_directory = config['output_directories']\n",
    "subdirectory_name = 'haddock_em_TB_ex'\n",
    "\n",
    "convert_tsv_to_excel(source_directory, target_directory, subdirectory_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec87360f-3b07-490f-b202-387b5d6e22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def convert_tsv_to_excel(source_directory, target_directory, subdirectory_name):\n",
    "    \"\"\"\n",
    "    Converts all TSV files found in the source_directory into Excel files\n",
    "    and saves them into the target_directory along with a specified subdirectory.\n",
    "\n",
    "    Args:\n",
    "    - source_directory (str): The path to the directory containing TSV files.\n",
    "    - target_directory (str): The path to the directory where Excel files will be saved.\n",
    "    - subdirectory_name (str): The name of the subdirectory where Excel files will be placed.\n",
    "    \"\"\"\n",
    "    # Append the subdirectory to the target directory\n",
    "    full_target_directory = os.path.join(target_directory, subdirectory_name)\n",
    "    \n",
    "    # Ensure the target directory exists\n",
    "    if not os.path.exists(full_target_directory):\n",
    "        os.makedirs(full_target_directory)\n",
    "    \n",
    "    # Iterate over all files in the source directory\n",
    "    for filename in os.listdir(source_directory):\n",
    "        if filename.endswith('.tsv'):\n",
    "            # Construct the full file paths\n",
    "            source_file_path = os.path.join(source_directory, filename)\n",
    "            # Change the file extension from .tsv to .xlsx for the output file\n",
    "            target_file_path = os.path.join(full_target_directory, filename.replace('.tsv', '.xlsx'))\n",
    "            \n",
    "            # Load the TSV file\n",
    "            df = pd.read_csv(source_file_path, sep='\\t')\n",
    "            # Save the dataframe to an Excel file\n",
    "            df.to_excel(target_file_path, index=False)\n",
    "            \n",
    "            # Optionally print a confirmation message\n",
    "            #print(f'Converted {filename} to Excel and saved as {os.path.basename(target_file_path)}')\n",
    "\n",
    "# Example usage\n",
    "source_directory = config['Haddock_md_directory']\n",
    "target_directory = config['output_directories']\n",
    "subdirectory_name = 'haddock_md_TB_ex'\n",
    "\n",
    "convert_tsv_to_excel(source_directory, target_directory, subdirectory_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2260a036-691b-4e4b-977e-6e6bc537780f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8C3H_DockQ_data_TB.xlsx and mdscoring_total_8C3H_TB.xlsx for PDB ID 8C3H\n",
      "Updated 8C3H_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8C3H\n",
      "Processing 7QOX_DockQ_data_TB.xlsx and mdscoring_total_7QOX_TB.xlsx for PDB ID 7QOX\n",
      "Updated 7QOX_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7QOX\n",
      "Processing 8F8Z_DockQ_data_TB.xlsx and mdscoring_total_8F8Z_TB.xlsx for PDB ID 8F8Z\n",
      "Updated 8F8Z_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8F8Z\n",
      "Processing 8CK5_DockQ_data_TB.xlsx and mdscoring_total_8CK5_TB.xlsx for PDB ID 8CK5\n",
      "Updated 8CK5_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8CK5\n",
      "Processing 8DGM_DockQ_data_TB.xlsx and mdscoring_total_8DGM_TB.xlsx for PDB ID 8DGM\n",
      "Updated 8DGM_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8DGM\n",
      "Processing 7XV1_DockQ_data_TB.xlsx and mdscoring_total_7XV1_TB.xlsx for PDB ID 7XV1\n",
      "Updated 7XV1_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7XV1\n",
      "Processing 8A68_DockQ_data_TB.xlsx and mdscoring_total_8A68_TB.xlsx for PDB ID 8A68\n",
      "Updated 8A68_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8A68\n",
      "Processing 7ZAX_DockQ_data_TB.xlsx and mdscoring_total_7ZAX_TB.xlsx for PDB ID 7ZAX\n",
      "Updated 7ZAX_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7ZAX\n",
      "Processing 7UDL_DockQ_data_TB.xlsx and mdscoring_total_7UDL_TB.xlsx for PDB ID 7UDL\n",
      "Updated 7UDL_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7UDL\n",
      "Processing 7PRX_DockQ_data_TB.xlsx and mdscoring_total_7PRX_TB.xlsx for PDB ID 7PRX\n",
      "Updated 7PRX_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7PRX\n",
      "Processing 7WQQ_DockQ_data_TB.xlsx and mdscoring_total_7WQQ_TB.xlsx for PDB ID 7WQQ\n",
      "Updated 7WQQ_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7WQQ\n",
      "Processing 7V1A_DockQ_data_TB.xlsx and mdscoring_total_7V1A_TB.xlsx for PDB ID 7V1A\n",
      "Updated 7V1A_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7V1A\n",
      "Processing 7SXF_DockQ_data_TB.xlsx and mdscoring_total_7SXF_TB.xlsx for PDB ID 7SXF\n",
      "Updated 7SXF_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7SXF\n",
      "Processing 7Z7C_DockQ_data_TB.xlsx and mdscoring_total_7Z7C_TB.xlsx for PDB ID 7Z7C\n",
      "Updated 7Z7C_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7Z7C\n",
      "Processing 8ESE_DockQ_data_TB.xlsx and mdscoring_total_8ESE_TB.xlsx for PDB ID 8ESE\n",
      "Updated 8ESE_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8ESE\n",
      "Processing 7XTY_DockQ_data_TB.xlsx and mdscoring_total_7XTY_TB.xlsx for PDB ID 7XTY\n",
      "Updated 7XTY_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7XTY\n",
      "Processing 7X8G_DockQ_data_TB.xlsx and mdscoring_total_7X8G_TB.xlsx for PDB ID 7X8G\n",
      "Updated 7X8G_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7X8G\n",
      "Processing 8IA5_DockQ_data_TB.xlsx and mdscoring_total_8IA5_TB.xlsx for PDB ID 8IA5\n",
      "Updated 8IA5_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8IA5\n",
      "Processing 8D7P_DockQ_data_TB.xlsx and mdscoring_total_8D7P_TB.xlsx for PDB ID 8D7P\n",
      "Updated 8D7P_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8D7P\n",
      "Processing 8hep_DockQ_data_TB.xlsx and mdscoring_total_8HEP_TB.xlsx for PDB ID 8HEP\n",
      "Updated 8hep_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8HEP\n",
      "Processing 7QWV_DockQ_data_TB.xlsx and mdscoring_total_7QWV_TB.xlsx for PDB ID 7QWV\n",
      "Updated 7QWV_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7QWV\n",
      "Processing 8ARE_DockQ_data_TB.xlsx and mdscoring_total_8ARE_TB.xlsx for PDB ID 8ARE\n",
      "Updated 8ARE_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8ARE\n",
      "Processing 7UI8_DockQ_data_TB.xlsx and mdscoring_total_7UI8_TB.xlsx for PDB ID 7UI8\n",
      "Updated 7UI8_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7UI8\n",
      "Processing 7YUE_DockQ_data_TB.xlsx and mdscoring_total_7YUE_TB.xlsx for PDB ID 7YUE\n",
      "Updated 7YUE_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7YUE\n",
      "Processing 8HDJ_DockQ_data_TB.xlsx and mdscoring_total_8HDJ_TB.xlsx for PDB ID 8HDJ\n",
      "Updated 8HDJ_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8HDJ\n",
      "Processing 8FK3_DockQ_data_TB.xlsx and mdscoring_total_8FK3_TB.xlsx for PDB ID 8FK3\n",
      "Updated 8FK3_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8FK3\n",
      "Processing 8DWK_DockQ_data_TB.xlsx and mdscoring_total_8DWK_TB.xlsx for PDB ID 8DWK\n",
      "Updated 8DWK_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8DWK\n",
      "Processing 8HLO_DockQ_data_TB.xlsx and mdscoring_total_8HLO_TB.xlsx for PDB ID 8HLO\n",
      "Updated 8HLO_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8HLO\n",
      "Processing 8CIR_DockQ_data_TB.xlsx and mdscoring_total_8CIR_TB.xlsx for PDB ID 8CIR\n",
      "Updated 8CIR_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8CIR\n",
      "Processing 8CCW_DockQ_data_TB.xlsx and mdscoring_total_8CCW_TB.xlsx for PDB ID 8CCW\n",
      "Updated 8CCW_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8CCW\n",
      "Processing 7UE2_DockQ_data_TB.xlsx and mdscoring_total_7UE2_TB.xlsx for PDB ID 7UE2\n",
      "Updated 7UE2_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7UE2\n",
      "Processing 7ZX4_DockQ_data_TB.xlsx and mdscoring_total_7ZX4_TB.xlsx for PDB ID 7ZX4\n",
      "Updated 7ZX4_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7ZX4\n",
      "Processing 7UW2_DockQ_data_TB.xlsx and mdscoring_total_7UW2_TB.xlsx for PDB ID 7UW2\n",
      "Updated 7UW2_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7UW2\n",
      "Processing 8EBL_DockQ_data_TB.xlsx and mdscoring_total_8EBL_TB.xlsx for PDB ID 8EBL\n",
      "Updated 8EBL_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8EBL\n",
      "Processing 7R2M_DockQ_data_TB.xlsx and mdscoring_total_7R2M_TB.xlsx for PDB ID 7R2M\n",
      "Updated 7R2M_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7R2M\n",
      "Processing 8CZK_DockQ_data_TB.xlsx and mdscoring_total_8CZK_TB.xlsx for PDB ID 8CZK\n",
      "Updated 8CZK_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8CZK\n",
      "Processing 7Y9C_DockQ_data_TB.xlsx and mdscoring_total_7Y9C_TB.xlsx for PDB ID 7Y9C\n",
      "Updated 7Y9C_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7Y9C\n",
      "Processing 8AFI_DockQ_data_TB.xlsx and mdscoring_total_8AFI_TB.xlsx for PDB ID 8AFI\n",
      "Updated 8AFI_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8AFI\n",
      "Processing 8D51_DockQ_data_TB.xlsx and mdscoring_total_8D51_TB.xlsx for PDB ID 8D51\n",
      "Updated 8D51_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8D51\n",
      "Processing 8IA4_DockQ_data_TB.xlsx and mdscoring_total_8IA4_TB.xlsx for PDB ID 8IA4\n",
      "Updated 8IA4_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8IA4\n",
      "Processing 7UDK_DockQ_data_TB.xlsx and mdscoring_total_7UDK_TB.xlsx for PDB ID 7UDK\n",
      "Updated 7UDK_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7UDK\n",
      "Processing 8FXQ_DockQ_data_TB.xlsx and mdscoring_total_8FXQ_TB.xlsx for PDB ID 8FXQ\n",
      "Updated 8FXQ_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8FXQ\n",
      "Processing 8EQ5_DockQ_data_TB.xlsx and mdscoring_total_8EQ5_TB.xlsx for PDB ID 8EQ5\n",
      "Updated 8EQ5_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8EQ5\n",
      "Processing 8OEP_DockQ_data_TB.xlsx and mdscoring_total_8OEP_TB.xlsx for PDB ID 8OEP\n",
      "Updated 8OEP_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8OEP\n",
      "Processing 8I3G_DockQ_data_TB.xlsx and mdscoring_total_8I3G_TB.xlsx for PDB ID 8I3G\n",
      "Updated 8I3G_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8I3G\n",
      "Processing 8BFT_DockQ_data_TB.xlsx and mdscoring_total_8BFT_TB.xlsx for PDB ID 8BFT\n",
      "Updated 8BFT_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8BFT\n",
      "Processing 8AHS_DockQ_data_TB.xlsx and mdscoring_total_8AHS_TB.xlsx for PDB ID 8AHS\n",
      "Updated 8AHS_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8AHS\n",
      "Processing 7SXJ_DockQ_data_TB.xlsx and mdscoring_total_7SXJ_TB.xlsx for PDB ID 7SXJ\n",
      "Updated 7SXJ_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7SXJ\n",
      "Processing 7Z6U_DockQ_data_TB.xlsx and mdscoring_total_7Z6U_TB.xlsx for PDB ID 7Z6U\n",
      "Updated 7Z6U_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7Z6U\n",
      "Processing 8C2P_DockQ_data_TB.xlsx and mdscoring_total_8C2P_TB.xlsx for PDB ID 8C2P\n",
      "Updated 8C2P_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8C2P\n",
      "Processing 8CZ9_DockQ_data_TB.xlsx and mdscoring_total_8CZ9_TB.xlsx for PDB ID 8CZ9\n",
      "Updated 8CZ9_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8CZ9\n",
      "Processing 7Y8F_DockQ_data_TB.xlsx and mdscoring_total_7Y8F_TB.xlsx for PDB ID 7Y8F\n",
      "Updated 7Y8F_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7Y8F\n",
      "Processing 8DVL_DockQ_data_TB.xlsx and mdscoring_total_8DVL_TB.xlsx for PDB ID 8DVL\n",
      "Updated 8DVL_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8DVL\n",
      "Processing 8BR9_DockQ_data_TB.xlsx and mdscoring_total_8BR9_TB.xlsx for PDB ID 8BR9\n",
      "Updated 8BR9_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8BR9\n",
      "Processing 7TO9_DockQ_data_TB.xlsx and mdscoring_total_7TO9_TB.xlsx for PDB ID 7TO9\n",
      "Updated 7TO9_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7TO9\n",
      "Processing 7XFG_DockQ_data_TB.xlsx and mdscoring_total_7XFG_TB.xlsx for PDB ID 7XFG\n",
      "Updated 7XFG_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7XFG\n",
      "Processing 7SQA_DockQ_data_TB.xlsx and mdscoring_total_7SQA_TB.xlsx for PDB ID 7SQA\n",
      "Updated 7SQA_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7SQA\n",
      "Processing 7Z5L_DockQ_data_TB.xlsx and mdscoring_total_7Z5L_TB.xlsx for PDB ID 7Z5L\n",
      "Updated 7Z5L_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7Z5L\n",
      "Processing 8B58_DockQ_data_TB.xlsx and mdscoring_total_8B58_TB.xlsx for PDB ID 8B58\n",
      "Updated 8B58_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 8B58\n",
      "Processing 7ZW4_DockQ_data_TB.xlsx and mdscoring_total_7ZW4_TB.xlsx for PDB ID 7ZW4\n",
      "Updated 7ZW4_DockQ_data_TB.xlsx with Hadd_md data for PDB ID 7ZW4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def extract_pdb_id_from_dockq(filename):\n",
    "    \"\"\"Extracts the PDB ID from a DockQ filename.\"\"\"\n",
    "    parts = filename.split('_')\n",
    "    return parts[0]  # PDB ID is the first part\n",
    "\n",
    "def extract_pdb_id_from_haddock(filename):\n",
    "    \"\"\"Extracts the PDB ID from a Haddock filename.\"\"\"\n",
    "    parts = filename.split('_')\n",
    "    return parts[2]  # PDB ID is after 'haddock_scoring'\n",
    "\n",
    "def copy_haddock_sheets_to_dockq(dockq_dir, haddock_dir, output_dir, subdirectory_name):\n",
    "    \"\"\"\n",
    "    Copies sheets from Haddock Excel files to corresponding DockQ Excel files\n",
    "    in a specified output directory including a subdirectory.\n",
    "\n",
    "    Args:\n",
    "    - dockq_dir (str): Directory containing DockQ files.\n",
    "    - haddock_dir (str): Directory containing Haddock files.\n",
    "    - output_dir (str): Base directory where output files will be saved.\n",
    "    - subdirectory_name (str): Subdirectory under the output directory where files will be placed.\n",
    "    \"\"\"\n",
    "    # Create full output directory path including subdirectory\n",
    "    full_output_dir = os.path.join(output_dir, subdirectory_name)\n",
    "    if not os.path.exists(full_output_dir):\n",
    "        os.makedirs(full_output_dir)\n",
    "\n",
    "    dockq_files = os.listdir(dockq_dir)\n",
    "    haddock_files = os.listdir(haddock_dir)\n",
    "    \n",
    "    # Map haddock files to their PDB IDs\n",
    "    haddock_map = {extract_pdb_id_from_haddock(f).upper(): f for f in haddock_files if 'mdscoring_total' in f}\n",
    "    \n",
    "    for dockq_file in dockq_files:\n",
    "        if dockq_file.endswith('_TB.xlsx') and 'DockQ_data' in dockq_file:\n",
    "            pdb_id = extract_pdb_id_from_dockq(dockq_file).upper()\n",
    "            if pdb_id in haddock_map:\n",
    "                dockq_path = os.path.join(dockq_dir, dockq_file)\n",
    "                haddock_path = os.path.join(haddock_dir, haddock_map[pdb_id])\n",
    "                output_path = os.path.join(full_output_dir, dockq_file)\n",
    "                \n",
    "                # Copy the DockQ file to the output directory if it's not already there\n",
    "                if not os.path.exists(output_path):\n",
    "                    shutil.copyfile(dockq_path, output_path)\n",
    "                \n",
    "                print(f\"Processing {dockq_file} and {haddock_map[pdb_id]} for PDB ID {pdb_id}\")\n",
    "                \n",
    "                haddock_df = pd.read_excel(haddock_path, sheet_name='Sheet1')\n",
    "                \n",
    "                with pd.ExcelWriter(output_path, engine='openpyxl', mode='a') as writer:\n",
    "                    book = load_workbook(output_path)\n",
    "                    writer.book = book\n",
    "                    if 'Hadd_md' in book.sheetnames:\n",
    "                        std = book['Hadd_md']\n",
    "                        book.remove(std)\n",
    "                    haddock_df.to_excel(writer, sheet_name='Hadd_md', index=False)\n",
    "                    \n",
    "                    print(f'Updated {dockq_file} with Hadd_md data for PDB ID {pdb_id}')\n",
    "            else:\n",
    "                print(f\"No matching Hadd_md file found for {dockq_file}\")\n",
    "\n",
    "dockq_dir = config['TB_uni']\n",
    "haddock_dir = os.path.join(config['output_directories'], 'haddock_md_TB_ex')\n",
    "output_dir = config['output_directories']\n",
    "subdirectory_name = 'haddock_md_TB_DockQ'  # Subdirectory name defined directly here\n",
    "\n",
    "copy_haddock_sheets_to_dockq(dockq_dir, haddock_dir, output_dir, subdirectory_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c1c69a-ba6e-498c-b496-569a748b4504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8C3H_DockQ_data_TB.xlsx and emscoring_total_8C3H_TB.xlsx for PDB ID 8C3H\n",
      "Updated 8C3H_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8C3H\n",
      "Processing 7QOX_DockQ_data_TB.xlsx and emscoring_total_7QOX_TB.xlsx for PDB ID 7QOX\n",
      "Updated 7QOX_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7QOX\n",
      "Processing 8F8Z_DockQ_data_TB.xlsx and emscoring_total_8F8Z_TB.xlsx for PDB ID 8F8Z\n",
      "Updated 8F8Z_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8F8Z\n",
      "Processing 8CK5_DockQ_data_TB.xlsx and emscoring_total_8CK5_TB.xlsx for PDB ID 8CK5\n",
      "Updated 8CK5_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8CK5\n",
      "Processing 8DGM_DockQ_data_TB.xlsx and emscoring_total_8DGM_TB.xlsx for PDB ID 8DGM\n",
      "Updated 8DGM_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8DGM\n",
      "Processing 7XV1_DockQ_data_TB.xlsx and emscoring_total_7XV1_TB.xlsx for PDB ID 7XV1\n",
      "Updated 7XV1_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7XV1\n",
      "Processing 8A68_DockQ_data_TB.xlsx and emscoring_total_8A68_TB.xlsx for PDB ID 8A68\n",
      "Updated 8A68_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8A68\n",
      "Processing 7ZAX_DockQ_data_TB.xlsx and emscoring_total_7ZAX_TB.xlsx for PDB ID 7ZAX\n",
      "Updated 7ZAX_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7ZAX\n",
      "Processing 7UDL_DockQ_data_TB.xlsx and emscoring_total_7UDL_TB.xlsx for PDB ID 7UDL\n",
      "Updated 7UDL_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7UDL\n",
      "Processing 7PRX_DockQ_data_TB.xlsx and emscoring_total_7PRX_TB.xlsx for PDB ID 7PRX\n",
      "Updated 7PRX_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7PRX\n",
      "Processing 7WQQ_DockQ_data_TB.xlsx and emscoring_total_7WQQ_TB.xlsx for PDB ID 7WQQ\n",
      "Updated 7WQQ_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7WQQ\n",
      "Processing 7V1A_DockQ_data_TB.xlsx and emscoring_total_7V1A_TB.xlsx for PDB ID 7V1A\n",
      "Updated 7V1A_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7V1A\n",
      "Processing 7SXF_DockQ_data_TB.xlsx and emscoring_total_7SXF_TB.xlsx for PDB ID 7SXF\n",
      "Updated 7SXF_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7SXF\n",
      "Processing 7Z7C_DockQ_data_TB.xlsx and emscoring_total_7Z7C_TB.xlsx for PDB ID 7Z7C\n",
      "Updated 7Z7C_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7Z7C\n",
      "Processing 8ESE_DockQ_data_TB.xlsx and emscoring_total_8ESE_TB.xlsx for PDB ID 8ESE\n",
      "Updated 8ESE_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8ESE\n",
      "Processing 7XTY_DockQ_data_TB.xlsx and emscoring_total_7XTY_TB.xlsx for PDB ID 7XTY\n",
      "Updated 7XTY_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7XTY\n",
      "Processing 7X8G_DockQ_data_TB.xlsx and emscoring_total_7X8G_TB.xlsx for PDB ID 7X8G\n",
      "Updated 7X8G_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7X8G\n",
      "Processing 8IA5_DockQ_data_TB.xlsx and emscoring_total_8IA5_TB.xlsx for PDB ID 8IA5\n",
      "Updated 8IA5_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8IA5\n",
      "Processing 8D7P_DockQ_data_TB.xlsx and emscoring_total_8D7P_TB.xlsx for PDB ID 8D7P\n",
      "Updated 8D7P_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8D7P\n",
      "Processing 8hep_DockQ_data_TB.xlsx and emscoring_total_8HEP_TB.xlsx for PDB ID 8HEP\n",
      "Updated 8hep_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8HEP\n",
      "Processing 7QWV_DockQ_data_TB.xlsx and emscoring_total_7QWV_TB.xlsx for PDB ID 7QWV\n",
      "Updated 7QWV_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7QWV\n",
      "Processing 8ARE_DockQ_data_TB.xlsx and emscoring_total_8ARE_TB.xlsx for PDB ID 8ARE\n",
      "Updated 8ARE_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8ARE\n",
      "Processing 7UI8_DockQ_data_TB.xlsx and emscoring_total_7UI8_TB.xlsx for PDB ID 7UI8\n",
      "Updated 7UI8_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7UI8\n",
      "Processing 7YUE_DockQ_data_TB.xlsx and emscoring_total_7YUE_TB.xlsx for PDB ID 7YUE\n",
      "Updated 7YUE_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7YUE\n",
      "Processing 8HDJ_DockQ_data_TB.xlsx and emscoring_total_8HDJ_TB.xlsx for PDB ID 8HDJ\n",
      "Updated 8HDJ_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8HDJ\n",
      "Processing 8FK3_DockQ_data_TB.xlsx and emscoring_total_8FK3_TB.xlsx for PDB ID 8FK3\n",
      "Updated 8FK3_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8FK3\n",
      "Processing 8DWK_DockQ_data_TB.xlsx and emscoring_total_8DWK_TB.xlsx for PDB ID 8DWK\n",
      "Updated 8DWK_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8DWK\n",
      "Processing 8HLO_DockQ_data_TB.xlsx and emscoring_total_8HLO_TB.xlsx for PDB ID 8HLO\n",
      "Updated 8HLO_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8HLO\n",
      "Processing 8CIR_DockQ_data_TB.xlsx and emscoring_total_8CIR_TB.xlsx for PDB ID 8CIR\n",
      "Updated 8CIR_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8CIR\n",
      "Processing 8CCW_DockQ_data_TB.xlsx and emscoring_total_8CCW_TB.xlsx for PDB ID 8CCW\n",
      "Updated 8CCW_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8CCW\n",
      "Processing 7UE2_DockQ_data_TB.xlsx and emscoring_total_7UE2_TB.xlsx for PDB ID 7UE2\n",
      "Updated 7UE2_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7UE2\n",
      "Processing 7ZX4_DockQ_data_TB.xlsx and emscoring_total_7ZX4_TB.xlsx for PDB ID 7ZX4\n",
      "Updated 7ZX4_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7ZX4\n",
      "Processing 7UW2_DockQ_data_TB.xlsx and emscoring_total_7UW2_TB.xlsx for PDB ID 7UW2\n",
      "Updated 7UW2_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7UW2\n",
      "Processing 8EBL_DockQ_data_TB.xlsx and emscoring_total_8EBL_TB.xlsx for PDB ID 8EBL\n",
      "Updated 8EBL_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8EBL\n",
      "Processing 7R2M_DockQ_data_TB.xlsx and emscoring_total_7R2M_TB.xlsx for PDB ID 7R2M\n",
      "Updated 7R2M_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7R2M\n",
      "Processing 8CZK_DockQ_data_TB.xlsx and emscoring_total_8CZK_TB.xlsx for PDB ID 8CZK\n",
      "Updated 8CZK_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8CZK\n",
      "Processing 7Y9C_DockQ_data_TB.xlsx and emscoring_total_7Y9C_TB.xlsx for PDB ID 7Y9C\n",
      "Updated 7Y9C_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7Y9C\n",
      "Processing 8AFI_DockQ_data_TB.xlsx and emscoring_total_8AFI_TB.xlsx for PDB ID 8AFI\n",
      "Updated 8AFI_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8AFI\n",
      "Processing 8D51_DockQ_data_TB.xlsx and emscoring_total_8D51_TB.xlsx for PDB ID 8D51\n",
      "Updated 8D51_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8D51\n",
      "Processing 8IA4_DockQ_data_TB.xlsx and emscoring_total_8IA4_TB.xlsx for PDB ID 8IA4\n",
      "Updated 8IA4_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8IA4\n",
      "Processing 7UDK_DockQ_data_TB.xlsx and emscoring_total_7UDK_TB.xlsx for PDB ID 7UDK\n",
      "Updated 7UDK_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7UDK\n",
      "Processing 8FXQ_DockQ_data_TB.xlsx and emscoring_total_8FXQ_TB.xlsx for PDB ID 8FXQ\n",
      "Updated 8FXQ_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8FXQ\n",
      "Processing 8EQ5_DockQ_data_TB.xlsx and emscoring_total_8EQ5_TB.xlsx for PDB ID 8EQ5\n",
      "Updated 8EQ5_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8EQ5\n",
      "Processing 8OEP_DockQ_data_TB.xlsx and emscoring_total_8OEP_TB.xlsx for PDB ID 8OEP\n",
      "Updated 8OEP_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8OEP\n",
      "Processing 8I3G_DockQ_data_TB.xlsx and emscoring_total_8I3G_TB.xlsx for PDB ID 8I3G\n",
      "Updated 8I3G_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8I3G\n",
      "Processing 8BFT_DockQ_data_TB.xlsx and emscoring_total_8BFT_TB.xlsx for PDB ID 8BFT\n",
      "Updated 8BFT_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8BFT\n",
      "Processing 8AHS_DockQ_data_TB.xlsx and emscoring_total_8AHS_TB.xlsx for PDB ID 8AHS\n",
      "Updated 8AHS_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8AHS\n",
      "Processing 7SXJ_DockQ_data_TB.xlsx and emscoring_total_7SXJ_TB.xlsx for PDB ID 7SXJ\n",
      "Updated 7SXJ_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7SXJ\n",
      "Processing 7Z6U_DockQ_data_TB.xlsx and emscoring_total_7Z6U_TB.xlsx for PDB ID 7Z6U\n",
      "Updated 7Z6U_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7Z6U\n",
      "Processing 8C2P_DockQ_data_TB.xlsx and emscoring_total_8C2P_TB.xlsx for PDB ID 8C2P\n",
      "Updated 8C2P_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8C2P\n",
      "Processing 8CZ9_DockQ_data_TB.xlsx and emscoring_total_8CZ9_TB.xlsx for PDB ID 8CZ9\n",
      "Updated 8CZ9_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8CZ9\n",
      "Processing 7Y8F_DockQ_data_TB.xlsx and emscoring_total_7Y8F_TB.xlsx for PDB ID 7Y8F\n",
      "Updated 7Y8F_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7Y8F\n",
      "Processing 8DVL_DockQ_data_TB.xlsx and emscoring_total_8DVL_TB.xlsx for PDB ID 8DVL\n",
      "Updated 8DVL_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8DVL\n",
      "Processing 8BR9_DockQ_data_TB.xlsx and emscoring_total_8BR9_TB.xlsx for PDB ID 8BR9\n",
      "Updated 8BR9_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8BR9\n",
      "Processing 7TO9_DockQ_data_TB.xlsx and emscoring_total_7TO9_TB.xlsx for PDB ID 7TO9\n",
      "Updated 7TO9_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7TO9\n",
      "Processing 7XFG_DockQ_data_TB.xlsx and emscoring_total_7XFG_TB.xlsx for PDB ID 7XFG\n",
      "Updated 7XFG_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7XFG\n",
      "Processing 7SQA_DockQ_data_TB.xlsx and emscoring_total_7SQA_TB.xlsx for PDB ID 7SQA\n",
      "Updated 7SQA_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7SQA\n",
      "Processing 7Z5L_DockQ_data_TB.xlsx and emscoring_total_7Z5L_TB.xlsx for PDB ID 7Z5L\n",
      "Updated 7Z5L_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7Z5L\n",
      "Processing 8B58_DockQ_data_TB.xlsx and emscoring_total_8B58_TB.xlsx for PDB ID 8B58\n",
      "Updated 8B58_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 8B58\n",
      "Processing 7ZW4_DockQ_data_TB.xlsx and emscoring_total_7ZW4_TB.xlsx for PDB ID 7ZW4\n",
      "Updated 7ZW4_DockQ_data_TB.xlsx with Hadd_em data for PDB ID 7ZW4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def extract_pdb_id_from_dockq(filename):\n",
    "    \"\"\"Extracts the PDB ID from a DockQ filename.\"\"\"\n",
    "    parts = filename.split('_')\n",
    "    return parts[0]  # PDB ID is the first part\n",
    "\n",
    "def extract_pdb_id_from_haddock(filename):\n",
    "    \"\"\"Extracts the PDB ID from a haddock filename.\"\"\"\n",
    "    parts = filename.split('_')\n",
    "    return parts[2]  # PDB ID is after 'haddock_scoring'\n",
    "\n",
    "def copy_haddock_sheets_to_dockq(dockq_dir, haddock_dir, output_dir, subdirectory_name):\n",
    "    \"\"\"\n",
    "    Copies sheets from Haddock Excel files to corresponding DockQ Excel files\n",
    "    into an output directory that includes a specified subdirectory.\n",
    "\n",
    "    Args:\n",
    "    - dockq_dir (str): Directory containing DockQ files.\n",
    "    - haddock_dir (str): Directory containing Haddock files.\n",
    "    - output_dir (str): Base directory where output files will be saved.\n",
    "    - subdirectory_name (str): The name of the subdirectory where files will be placed.\n",
    "    \"\"\"\n",
    "    full_output_dir = os.path.join(output_dir, subdirectory_name)\n",
    "    if not os.path.exists(full_output_dir):\n",
    "        os.makedirs(full_output_dir)\n",
    "    \n",
    "    dockq_files = os.listdir(dockq_dir)\n",
    "    haddock_files = os.listdir(haddock_dir)\n",
    "    \n",
    "    # Map haddock files to their PDB IDs\n",
    "    haddock_map = {extract_pdb_id_from_haddock(f).upper(): f for f in haddock_files if 'emscoring_total' in f}\n",
    "    \n",
    "    for dockq_file in dockq_files:\n",
    "        if dockq_file.endswith('_TB.xlsx') and 'DockQ_data' in dockq_file:\n",
    "            pdb_id = extract_pdb_id_from_dockq(dockq_file).upper()\n",
    "            if pdb_id in haddock_map:\n",
    "                dockq_path = os.path.join(dockq_dir, dockq_file)\n",
    "                haddock_path = os.path.join(haddock_dir, haddock_map[pdb_id])\n",
    "                output_path = os.path.join(full_output_dir, dockq_file)\n",
    "                \n",
    "                # Copy the DockQ file to the output directory if it's not already there\n",
    "                if not os.path.exists(output_path):\n",
    "                    shutil.copyfile(dockq_path, output_path)\n",
    "                \n",
    "                print(f\"Processing {dockq_file} and {haddock_map[pdb_id]} for PDB ID {pdb_id}\")\n",
    "                \n",
    "                haddock_df = pd.read_excel(haddock_path, sheet_name='Sheet1')\n",
    "                \n",
    "                with pd.ExcelWriter(output_path, engine='openpyxl', mode='a') as writer:\n",
    "                    book = load_workbook(output_path)\n",
    "                    writer.book = book\n",
    "                    if 'Hadd_em' in book.sheetnames:\n",
    "                        std = book['Hadd_em']\n",
    "                        book.remove(std)\n",
    "                    haddock_df.to_excel(writer, sheet_name='Hadd_em', index=False)\n",
    "                    \n",
    "                    print(f'Updated {dockq_file} with Hadd_em data for PDB ID {pdb_id}')\n",
    "            else:\n",
    "                print(f\"No matching Hadd_em file found for {dockq_file}\")\n",
    "\n",
    "dockq_dir = config['TB_uni']\n",
    "haddock_dir = os.path.join(config['output_directories'], 'haddock_em_TB_ex')\n",
    "output_dir = config['output_directories']\n",
    "subdirectory_name = 'haddock_em_TB_DockQ'\n",
    "\n",
    "copy_haddock_sheets_to_dockq(dockq_dir, haddock_dir, output_dir, subdirectory_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d6717fb-5556-4118-a5a4-36da1cf854f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def calculate_spearman_for_directory(directory_path, output_file):\n",
    "    # List to store results\n",
    "    results = []\n",
    "    missing_sheet_files = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            try:\n",
    "                # Load the Excel file\n",
    "                excel_data = pd.ExcelFile(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'An error occurred while loading the file \"{filename}\": {e}')\n",
    "                continue\n",
    "\n",
    "            # Check if the expected sheets exist\n",
    "            if 'Sheet' in excel_data.sheet_names and 'Hadd_em' in excel_data.sheet_names:\n",
    "                # Load the data from each sheet\n",
    "                sheet_data = pd.read_excel(file_path, sheet_name='Sheet')\n",
    "                hadd_data = pd.read_excel(file_path, sheet_name='Hadd_em')\n",
    "\n",
    "                # Extract relevant columns and rename them for clarity\n",
    "                sheet_relevant = sheet_data[['AlphaFold Rank', 'DockQ Rank']]\n",
    "                hadd_relevant = hadd_data[['old_rank', '#']].copy()\n",
    "\n",
    "                # Create a mapping from 'AlphaFold Rank' to 'DockQ Rank'\n",
    "                alpha_to_dockq_map = sheet_relevant.set_index('AlphaFold Rank')['DockQ Rank'].to_dict()\n",
    "\n",
    "                # Map 'old_rank' in hadd_relevant to 'DockQ Rank' using the created mapping\n",
    "                hadd_relevant.loc[:, 'DockQ Rank'] = hadd_relevant['old_rank'].map(alpha_to_dockq_map)\n",
    "\n",
    "                # Drop rows with NaN values in 'DockQ Rank'\n",
    "                filtered_hadd_df = hadd_relevant.dropna(subset=['DockQ Rank'])\n",
    "\n",
    "                # Calculate the Spearman correlation\n",
    "                if not filtered_hadd_df.empty:\n",
    "                    spearman_corr, _ = spearmanr(filtered_hadd_df['#'], filtered_hadd_df['DockQ Rank'])\n",
    "\n",
    "                    # Append the result to the list\n",
    "                    results.append({'File Name': filename, 'Spearman Correlation': spearman_corr})\n",
    "                else:\n",
    "                    results.append({'File Name': filename, 'Spearman Correlation': None})\n",
    "            else:\n",
    "                missing_sheet_files.append(filename)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save the results to an Excel file\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "\n",
    "    # Print files missing the required sheets\n",
    "    if missing_sheet_files:\n",
    "        print(\"Files missing the 'Sheet' or 'Hadd_em' sheet:\")\n",
    "        for file in missing_sheet_files:\n",
    "            print(file)\n",
    "\n",
    "# Usage\n",
    "directory_path = os.path.join(config['output_directories'], 'haddock_em_TB_DockQ')\n",
    "output_directory = config['Spearman_Correlation_directory_TB']\n",
    "output_file = os.path.join(output_directory, \"correlations_hadd_em_TB.xlsx\")\n",
    "\n",
    "calculate_spearman_for_directory(directory_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18d75b1-bff3-4b41-837e-5bff4ec888e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Hadd_em_Spearman Correlation: 60.00%\n",
      "Negative Hadd_em_Spearman Correlation: 40.00%\n",
      "Average Hadd_em_Spearman Correlation: 0.04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_positive_negative_percentages_and_average(file_path):\n",
    "    # Load the Excel file\n",
    "    data = pd.read_excel(file_path)\n",
    "    \n",
    "    # Count the total number of entries\n",
    "    total_entries = len(data['Spearman Correlation'])\n",
    "    \n",
    "    # Count the number of positive and negative Hadd_em_Spearman Correlation values\n",
    "    positive_count = data[data['Spearman Correlation'] > 0].shape[0]\n",
    "    negative_count = data[data['Spearman Correlation'] < 0].shape[0]\n",
    "    \n",
    "    # Calculate percentages\n",
    "    positive_percentage = (positive_count / total_entries) * 100\n",
    "    negative_percentage = (negative_count / total_entries) * 100\n",
    "    \n",
    "    # Calculate the average of Hadd_em_Spearman Correlation values\n",
    "    average_correlation = data['Spearman Correlation'].mean()\n",
    "    \n",
    "    return positive_percentage, negative_percentage, average_correlation\n",
    "\n",
    "# Example usage\n",
    "file_path = f\"{config['Spearman_Correlation_directory_TB']}/correlations_hadd_em_TB.xlsx\"\n",
    "positive_percentage, negative_percentage, average_correlation = calculate_positive_negative_percentages_and_average(file_path)\n",
    "print(f\"Positive Hadd_em_Spearman Correlation: {positive_percentage:.2f}%\")\n",
    "print(f\"Negative Hadd_em_Spearman Correlation: {negative_percentage:.2f}%\")\n",
    "print(f\"Average Hadd_em_Spearman Correlation: {average_correlation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3cdb711-0163-4813-8da4-b67368acc8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to /Users/neginmanshour/Desktop/Protein_Peptide_Evaluation/Loss/TB_Loss/Haddock_emscore_TB.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the Excel files\n",
    "directory_path = f\"{config['output_directories']}/haddock_em_TB_DockQ\"\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# List all Excel files in the directory\n",
    "excel_files = [file for file in os.listdir(directory_path) if file.endswith('.xlsx')]\n",
    "\n",
    "for file_name in excel_files:\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Extract pdb_id from file name\n",
    "    pdb_id = file_name.split('_')[0]\n",
    "\n",
    "    # Load data from \"Foldx\" sheet\n",
    "    foldx_df = pd.read_excel(file_path, sheet_name='Hadd_em')\n",
    "    structure_name_for_rank_zero = foldx_df[foldx_df['#'] == 0]['structure_name'].iloc[0].replace('_clean_haddock.pdb', '')\n",
    "\n",
    "    # Load data from \"Sheet\" sheet\n",
    "    sheet_df = pd.read_excel(file_path, sheet_name='Sheet')\n",
    "\n",
    "    # Highest DockQ score\n",
    "    highest_dockq_score = sheet_df['DockQ'].max()\n",
    "\n",
    "    # DockQ score for the structure from Foldx\n",
    "    highest_foldx_dockq_score = sheet_df[sheet_df['File Name'].str.contains(structure_name_for_rank_zero)]['DockQ'].max()\n",
    "\n",
    "    # Calculate Loss\n",
    "    score_Loss = highest_dockq_score - highest_foldx_dockq_score\n",
    "\n",
    "    # Append results\n",
    "    results.append([pdb_id, highest_dockq_score, highest_foldx_dockq_score, score_Loss])\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results, columns=['File Name', 'DockQ', 'Haddock_emscore ranked', 'Loss'])\n",
    "\n",
    "# Save the results into a new Excel file\n",
    "output_directory = config[\"DockQ_Loss_directory_TB\"]\n",
    "output_path = os.path.join(output_directory, 'Haddock_emscore_TB.xlsx')\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Results have been saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269bda9a-ca34-4db6-b5a1-501e9b966091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def calculate_spearman_for_directory(directory_path, output_file):\n",
    "    # List to store results\n",
    "    results = []\n",
    "    missing_sheet_files = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            try:\n",
    "                # Load the Excel file\n",
    "                excel_data = pd.ExcelFile(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'An error occurred while loading the file \"{filename}\": {e}')\n",
    "                continue\n",
    "\n",
    "            # Check if the expected sheets exist\n",
    "            if 'Sheet' in excel_data.sheet_names and 'Hadd_md' in excel_data.sheet_names:\n",
    "                # Load the data from each sheet\n",
    "                sheet_data = pd.read_excel(file_path, sheet_name='Sheet')\n",
    "                hadd_data = pd.read_excel(file_path, sheet_name='Hadd_md')\n",
    "\n",
    "                # Extract relevant columns and rename them for clarity\n",
    "                sheet_relevant = sheet_data[['AlphaFold Rank', 'DockQ Rank']]\n",
    "                hadd_relevant = hadd_data[['old_rank', '#']].copy()\n",
    "\n",
    "                # Create a mapping from 'AlphaFold Rank' to 'DockQ Rank'\n",
    "                alpha_to_dockq_map = sheet_relevant.set_index('AlphaFold Rank')['DockQ Rank'].to_dict()\n",
    "\n",
    "                # Map 'old_rank' in hadd_relevant to 'DockQ Rank' using the created mapping\n",
    "                hadd_relevant.loc[:, 'DockQ Rank'] = hadd_relevant['old_rank'].map(alpha_to_dockq_map)\n",
    "\n",
    "                # Drop rows with NaN values in 'DockQ Rank'\n",
    "                filtered_hadd_df = hadd_relevant.dropna(subset=['DockQ Rank'])\n",
    "\n",
    "                # Calculate the Spearman correlation\n",
    "                if not filtered_hadd_df.empty:\n",
    "                    spearman_corr, _ = spearmanr(filtered_hadd_df['#'], filtered_hadd_df['DockQ Rank'])\n",
    "\n",
    "                    # Append the result to the list\n",
    "                    results.append({'File Name': filename, 'Spearman Correlation': spearman_corr})\n",
    "                else:\n",
    "                    results.append({'File Name': filename, 'Spearman Correlation': None})\n",
    "            else:\n",
    "                missing_sheet_files.append(filename)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save the results to an Excel file\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "\n",
    "    # Print files missing the required sheets\n",
    "    if missing_sheet_files:\n",
    "        print(\"Files missing the 'Sheet' or 'Hadd_md' sheet:\")\n",
    "        for file in missing_sheet_files:\n",
    "            print(file)\n",
    "\n",
    "directory_path = os.path.join(config['output_directories'], 'haddock_md_TB_DockQ')\n",
    "output_directory = config['Spearman_Correlation_directory_TB']\n",
    "output_file = os.path.join(output_directory, \"correlations_hadd_md_TB.xlsx\")\n",
    "\n",
    "calculate_spearman_for_directory(directory_path, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbebe07-e429-41f6-ba7b-3d070cfcd0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Hadd_em_Spearman Correlation: 68.33%\n",
      "Negative Hadd_em_Spearman Correlation: 31.67%\n",
      "Average Hadd_em_Spearman Correlation: 0.10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_positive_negative_percentages_and_average(file_path):\n",
    "    # Load the Excel file\n",
    "    data = pd.read_excel(file_path)\n",
    "    \n",
    "    # Count the total number of entries\n",
    "    total_entries = len(data['Spearman Correlation'])\n",
    "    \n",
    "    # Count the number of positive and negative Hadd_em_Spearman Correlation values\n",
    "    positive_count = data[data['Spearman Correlation'] > 0].shape[0]\n",
    "    negative_count = data[data['Spearman Correlation'] < 0].shape[0]\n",
    "    \n",
    "    # Calculate percentages\n",
    "    positive_percentage = (positive_count / total_entries) * 100\n",
    "    negative_percentage = (negative_count / total_entries) * 100\n",
    "    \n",
    "    # Calculate the average of Hadd_em_Spearman Correlation values\n",
    "    average_correlation = data['Spearman Correlation'].mean()\n",
    "    \n",
    "    return positive_percentage, negative_percentage, average_correlation\n",
    "\n",
    "# Example usage\n",
    "file_path = f\"{config['Spearman_Correlation_directory_TB']}/correlations_hadd_md_TB.xlsx\"\n",
    "positive_percentage, negative_percentage, average_correlation = calculate_positive_negative_percentages_and_average(file_path)\n",
    "print(f\"Positive Hadd_em_Spearman Correlation: {positive_percentage:.2f}%\")\n",
    "print(f\"Negative Hadd_em_Spearman Correlation: {negative_percentage:.2f}%\")\n",
    "print(f\"Average Hadd_em_Spearman Correlation: {average_correlation:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4a453d-d48f-48bd-94eb-dadca7a6dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to /Users/neginmanshour/Desktop/Protein_Peptide_Evaluation/Loss/TB_Loss/Haddock_mdscore_TB.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the Excel files\n",
    "#directory_path = '/Users/neginmanshour/Desktop/Haddock_Evaluation/Data/TB/haddock_md_TB_DockQ'\n",
    "directory_path = f\"{config['output_directories']}/haddock_md_TB_DockQ\"\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# List all Excel files in the directory\n",
    "excel_files = [file for file in os.listdir(directory_path) if file.endswith('.xlsx')]\n",
    "\n",
    "for file_name in excel_files:\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Extract pdb_id from file name\n",
    "    pdb_id = file_name.split('_')[0]\n",
    "\n",
    "    # Load data from \"Foldx\" sheet\n",
    "    foldx_df = pd.read_excel(file_path, sheet_name='Hadd_md')\n",
    "    structure_name_for_rank_zero = foldx_df[foldx_df['#'] == 0]['structure_name'].iloc[0].replace('_clean_haddock.pdb', '')\n",
    "\n",
    "    # Load data from \"Sheet\" sheet\n",
    "    sheet_df = pd.read_excel(file_path, sheet_name='Sheet')\n",
    "\n",
    "    # Highest DockQ score\n",
    "    highest_dockq_score = sheet_df['DockQ'].max()\n",
    "\n",
    "    # DockQ score for the structure from Foldx\n",
    "    highest_foldx_dockq_score = sheet_df[sheet_df['File Name'].str.contains(structure_name_for_rank_zero)]['DockQ'].max()\n",
    "\n",
    "    # Calculate Loss\n",
    "    score_Loss = highest_dockq_score - highest_foldx_dockq_score\n",
    "\n",
    "    # Append results\n",
    "    results.append([pdb_id, highest_dockq_score, highest_foldx_dockq_score, score_Loss])\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results, columns=['File Name', 'DockQ', 'Haddock_emscore ranked', 'Loss'])\n",
    "\n",
    "# Save the results into a new Excel file\n",
    "output_directory = config[\"DockQ_Loss_directory_TB\"]\n",
    "output_path = os.path.join(output_directory, 'Haddock_mdscore_TB.xlsx')\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Results have been saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d74c5a-56a4-4a54-b67f-1a1aedf30f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
